{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**KDE-ISOMAP for unsupervised metric learning**"
      ],
      "metadata": {
        "id": "NbFoW7Fl3b0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DAYo4jc3a7Y",
        "outputId": "b0d059e1-ea4d-4a26-ddd9-633a2ea0dd3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 150\n",
            "Number of features: 4\n",
            "Number of classes: 3\n",
            "\n",
            "\n",
            "Supervised classification for PCA features\n",
            "\n",
            "KNN accuracy:  0.96\n",
            "SVM accuracy:  0.9466666666666667\n",
            "QDA accuracy:  0.9466666666666667\n",
            "Silhouette coefficient:  0.4013868139636179\n",
            "Maximum accuracy:  0.96\n",
            "\n",
            "\n",
            "Supervised classification for KPCA features\n",
            "\n",
            "KNN accuracy:  0.8666666666666667\n",
            "SVM accuracy:  0.8\n",
            "QDA accuracy:  0.8\n",
            "Silhouette coefficient:  0.4692355903816291\n",
            "Maximum accuracy:  0.8666666666666667\n",
            "\n",
            "\n",
            "Supervised classification for ISOMAP features\n",
            "\n",
            "KNN accuracy:  0.9066666666666666\n",
            "SVM accuracy:  0.92\n",
            "QDA accuracy:  0.9066666666666666\n",
            "Silhouette coefficient:  0.45248295510815817\n",
            "Maximum accuracy:  0.92\n",
            "\n",
            "\n",
            "Supervised classification for LLE features\n",
            "\n",
            "KNN accuracy:  0.9733333333333334\n",
            "SVM accuracy:  0.5333333333333333\n",
            "QDA accuracy:  0.9733333333333334\n",
            "Silhouette coefficient:  0.3652705042958714\n",
            "Maximum accuracy:  0.9733333333333334\n",
            "\n",
            "\n",
            "Supervised classification for Lap. Eig. features\n",
            "\n",
            "KNN accuracy:  0.8266666666666667\n",
            "SVM accuracy:  0.4266666666666667\n",
            "QDA accuracy:  0.84\n",
            "Silhouette coefficient:  0.541690157906486\n",
            "Maximum accuracy:  0.84\n",
            "\n",
            "Percentil = 1\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.5333333333333333\n",
            "SVM accuracy:  0.38666666666666666\n",
            "QDA accuracy:  0.5466666666666666\n",
            "Silhouette coefficient:  -0.19916418652702905\n",
            "Maximum accuracy:  0.5466666666666666\n",
            "\n",
            "Percentil = 2\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.7466666666666667\n",
            "SVM accuracy:  0.8\n",
            "QDA accuracy:  0.68\n",
            "Silhouette coefficient:  0.18147868302916811\n",
            "Maximum accuracy:  0.8\n",
            "\n",
            "Percentil = 3\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9466666666666667\n",
            "SVM accuracy:  0.9066666666666666\n",
            "QDA accuracy:  0.8133333333333334\n",
            "Silhouette coefficient:  0.04315151257411782\n",
            "Maximum accuracy:  0.9466666666666667\n",
            "\n",
            "Percentil = 4\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9066666666666666\n",
            "SVM accuracy:  0.8666666666666667\n",
            "QDA accuracy:  0.8533333333333334\n",
            "Silhouette coefficient:  0.5018981596718846\n",
            "Maximum accuracy:  0.9066666666666666\n",
            "\n",
            "Percentil = 5\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.8933333333333333\n",
            "SVM accuracy:  0.88\n",
            "QDA accuracy:  0.88\n",
            "Silhouette coefficient:  0.5370886597744234\n",
            "Maximum accuracy:  0.8933333333333333\n",
            "\n",
            "Percentil = 6\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9733333333333334\n",
            "SVM accuracy:  0.8533333333333334\n",
            "QDA accuracy:  0.8266666666666667\n",
            "Silhouette coefficient:  0.5818747492545532\n",
            "Maximum accuracy:  0.9733333333333334\n",
            "\n",
            "Percentil = 7\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.96\n",
            "SVM accuracy:  0.9333333333333333\n",
            "QDA accuracy:  0.88\n",
            "Silhouette coefficient:  0.5805659305656757\n",
            "Maximum accuracy:  0.96\n",
            "\n",
            "Percentil = 8\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.96\n",
            "SVM accuracy:  0.9333333333333333\n",
            "QDA accuracy:  0.9066666666666666\n",
            "Silhouette coefficient:  0.5699426738568449\n",
            "Maximum accuracy:  0.96\n",
            "\n",
            "Percentil = 9\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.96\n",
            "SVM accuracy:  0.9333333333333333\n",
            "QDA accuracy:  0.9066666666666666\n",
            "Silhouette coefficient:  0.5399439306272343\n",
            "Maximum accuracy:  0.96\n",
            "\n",
            "Percentil = 10\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9466666666666667\n",
            "SVM accuracy:  0.8666666666666667\n",
            "QDA accuracy:  0.8533333333333334\n",
            "Silhouette coefficient:  0.533001770663875\n",
            "Maximum accuracy:  0.9466666666666667\n",
            "\n",
            "Percentil = 11\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9866666666666667\n",
            "SVM accuracy:  0.8933333333333333\n",
            "QDA accuracy:  0.8533333333333334\n",
            "Silhouette coefficient:  0.596924193879014\n",
            "Maximum accuracy:  0.9866666666666667\n",
            "\n",
            "Percentil = 12\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9733333333333334\n",
            "SVM accuracy:  0.9333333333333333\n",
            "QDA accuracy:  0.9066666666666666\n",
            "Silhouette coefficient:  0.5590731612637453\n",
            "Maximum accuracy:  0.9733333333333334\n",
            "\n",
            "Percentil = 13\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9866666666666667\n",
            "SVM accuracy:  0.8666666666666667\n",
            "QDA accuracy:  0.96\n",
            "Silhouette coefficient:  0.5813124546671873\n",
            "Maximum accuracy:  0.9866666666666667\n",
            "\n",
            "Percentil = 14\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.9866666666666667\n",
            "SVM accuracy:  0.8666666666666667\n",
            "QDA accuracy:  0.9466666666666667\n",
            "Silhouette coefficient:  0.573154341452183\n",
            "Maximum accuracy:  0.9866666666666667\n",
            "\n",
            "Percentil = 15\n",
            "\n",
            "Supervised classification for NP-ISO features\n",
            "\n",
            "KNN accuracy:  0.96\n",
            "SVM accuracy:  0.76\n",
            "QDA accuracy:  0.8666666666666667\n",
            "Silhouette coefficient:  0.5781755302649325\n",
            "Maximum accuracy:  0.96\n",
            "\n",
            "Percentil = 16\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "A kernel density estimation based ISOMAP for metric learning\n",
        "\n",
        "Created on Wed May 24 16:59:33 2022\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Imports\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "import sklearn.neighbors as sknn\n",
        "import sklearn.utils.graph as sksp\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import networkx as nx\n",
        "#from KDEpy import FFTKDE\n",
        "from numpy.linalg import inv\n",
        "from scipy.stats import iqr\n",
        "from scipy.stats import gaussian_kde\n",
        "from statsmodels.nonparametric.bandwidths import bw_scott\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# To avoid unnecessary warning messages\n",
        "warnings.simplefilter(action='ignore')\n",
        "\n",
        "#%%%%%%%%%%%%% Functions\n",
        "\n",
        "'''\n",
        "Computes the symmetrized KL-divergence (relative entropy) between\n",
        "2 densities in a non-parametric way\n",
        "'''\n",
        "def divergenciaKL(dens1, dens2):\n",
        "    k1 = len(dens1)\n",
        "    k2 = len(dens2)\n",
        "    \n",
        "    # Remove zeros and too small values\n",
        "    dens1[dens1<10**(-300)] = 10**(-300)\n",
        "    dens2[dens2<10**(-300)] = 10**(-300)\n",
        "    \n",
        "    if k1 != k2:\n",
        "        return -1\n",
        "    else:\n",
        "        dKL12 = sum(dens1*np.log(dens1/dens2))/k1\n",
        "        dKL21 = sum(dens2*np.log(dens2/dens1))/k2\n",
        "        dKL = 0.5*(dKL12 + dKL21)\n",
        "        \n",
        "        return dKL\n",
        "    \n",
        "'''\n",
        "Estimation of h (bandwidth) through Silverman method\n",
        "https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
        "'''\n",
        "def Silverman(dados):    \n",
        "    num = len(dados)\n",
        "    # std. dev. is not robust to outliers\n",
        "    # mean absolute deviation (MAD) instead?\n",
        "    dp = dados.std()    \n",
        "    inter = iqr(dados)/1.34\n",
        "    hs = 0.9*min(dp, inter)*num**(-0.2)\n",
        "    # h cannot be zero, nor too close to zero\n",
        "    hs = max(hs, 0.05)\n",
        "\n",
        "    return hs\n",
        "\n",
        "'''\n",
        " Performs a grid search cross-validation to optimize the value h\n",
        "'''\n",
        "def CrossValidation(dados):    \n",
        "    # Search in the interval [0, 1] (20 points) \n",
        "    params = {'bandwidth': np.linspace(0, 1, 20)}\n",
        "    grid = GridSearchCV(KernelDensity(), params)\n",
        "    grid.fit(dados)\n",
        "    # h cannot be zero, nor too close to zero\n",
        "    hcv = max(grid.best_estimator_.bandwidth, 0.05)\n",
        "    \n",
        "    return hcv\n",
        "\n",
        "'''\n",
        " Regular PCA implementation\n",
        "'''\n",
        "def myPCA(dados):\n",
        "    # Eigenvalues and eigenvectors of the covariance matrix\n",
        "    v1, w1 = np.linalg.eig(np.cov(dados.T))\n",
        "\n",
        "    # Sort the eigenvalues\n",
        "    ordem = v1.argsort()\n",
        "\n",
        "    # Select the two eigenvectors associated to the two largest eigenvalues\n",
        "    maior_autovetor1 = w1[:, ordem[-1]]\n",
        "    segundo_maior1 = w1[:, ordem[-2]]\n",
        "\n",
        "    # Projection matrix\n",
        "    Wpca = np.array([maior_autovetor1, segundo_maior1])\n",
        "\n",
        "    # Linear projection into the 2D subspace\n",
        "    novos_dados_pca = np.dot(Wpca, dados.T)\n",
        "\n",
        "    return novos_dados_pca\n",
        "    \n",
        "\n",
        "'''\n",
        "Non-parametric estimation of the local densities \n",
        "Parameters:\n",
        " dados: data matrix\n",
        " A: adjacency matrix of the KNN graph\n",
        " method: string that controls the bandwidth estimation\n",
        "               'none, silverman, silverman/3, scott, crossval, isj'\n",
        "'''\n",
        "def KernelDensityEstimation(dados, A, method, h=0.1, delta=256):\n",
        "    # Number of points\n",
        "    n = dados.shape[0]\n",
        "    # Number of features\n",
        "    m = dados.shape[1]\n",
        "    \n",
        "    # 3D matrix used to store the local densities\n",
        "    # n matrices of dimensions delta x m\n",
        "    densidades = np.zeros((n, delta, m))\n",
        "\n",
        "    # Determine the minimum and maximum value in all features\n",
        "    lista = []\n",
        "    for i in range(m):\n",
        "        F = dados[:, i]\n",
        "        lista.append(F.min())\n",
        "        lista.append(F.max())\n",
        "    \n",
        "    # We adjust the x axis so that all local densities are plotted in the same interval\n",
        "    minimo = min(lista)\n",
        "    maximo = max(lista)\n",
        "\n",
        "    # Non-parametric estimation of the local densities\n",
        "    for i in range(n):\n",
        "        vizinhos = A[i, :]\n",
        "        indices = vizinhos.nonzero()[0]\n",
        "        amostras = dados[indices]\n",
        "    \n",
        "        for j in range(m):\n",
        "            F = amostras[:, j]\n",
        "        \n",
        "            X = F.reshape(-1, 1)\n",
        "            \n",
        "            if method == 'isj':\n",
        "                # Bandwidth estimation through Improved Sheather-Jones\n",
        "                # More details in: https://arxiv.org/pdf/1011.2602.pdf\n",
        "                kde = FFTKDE(kernel='gaussian', bw='ISJ')\n",
        "                kde.fit(X)\n",
        "\n",
        "                x_plot = np.linspace(minimo-0.1, maximo+0.1, delta)\n",
        "                pontos = x_plot.reshape(-1, 1)\n",
        "    \n",
        "                dens = kde.evaluate(pontos)\n",
        "          \n",
        "            elif method == 'crossval':    \n",
        "                # Cross-Validation rule\n",
        "                h = CrossValidation(X)\n",
        "                        \n",
        "                kde = KernelDensity(kernel='gaussian', bandwidth=h) \n",
        "                kde.fit(X)\n",
        "\n",
        "                x_plot = np.linspace(minimo, maximo, delta)\n",
        "                pontos = x_plot.reshape(-1, 1)\n",
        "\n",
        "                log_dens = kde.score_samples(pontos)\n",
        "                dens = np.exp(log_dens)\n",
        "            \n",
        "            elif method == 'silverman':\n",
        "                # Silverman\n",
        "                h = Silverman(X)\n",
        "                \n",
        "                kde = KernelDensity(kernel='gaussian', bandwidth=h) \n",
        "                kde.fit(X)\n",
        "\n",
        "                x_plot = np.linspace(minimo, maximo, delta)\n",
        "                pontos = x_plot.reshape(-1, 1)\n",
        "\n",
        "                log_dens = kde.score_samples(pontos)\n",
        "                dens = np.exp(log_dens)\n",
        "                \n",
        "            elif method == 'silverman/3':\n",
        "                # Silverman\n",
        "                h = Silverman(X)/3.0\n",
        "                \n",
        "                kde = KernelDensity(kernel='gaussian', bandwidth=h) \n",
        "                kde.fit(X)\n",
        "\n",
        "                x_plot = np.linspace(minimo, maximo, delta)\n",
        "                pontos = x_plot.reshape(-1, 1)\n",
        "\n",
        "                log_dens = kde.score_samples(pontos)\n",
        "                dens = np.exp(log_dens)\n",
        "                \n",
        "            elif method == 'scott':\n",
        "                \n",
        "                # Método antigo: na maioria dos casos resulta em erro (matriz de covariância é singular)\n",
        "                #kde = gaussian_kde(F, bw_method='scott')\n",
        "                #x_plot = np.linspace(minimo, maximo, delta)\n",
        "                #dens = kde(x_plot)\n",
        "\n",
        "                # Método novo (baseado em FFT)\n",
        "                h = bw_scott(F)     # estima o h pelo método de scott\n",
        "                if h < 0.05:\n",
        "                    h = 0.1\n",
        "                kde = sm.nonparametric.KDEUnivariate(F)\n",
        "                kde.fit(bw=h)\n",
        "                x_plot = np.linspace(minimo, maximo, delta)\n",
        "                dens = kde.evaluate(x_plot)\n",
        "                \n",
        "            else: # none (constant h, the same for all densities)\n",
        "            \n",
        "                kde = KernelDensity(kernel='gaussian', bandwidth=h) \n",
        "                kde.fit(X)\n",
        "\n",
        "                x_plot = np.linspace(minimo, maximo, delta)\n",
        "                pontos = x_plot.reshape(-1, 1)\n",
        "\n",
        "                log_dens = kde.score_samples(pontos)\n",
        "                dens = np.exp(log_dens)\n",
        "            \n",
        "            densidades[i, :, j] = dens\n",
        "            \n",
        "    return densidades\n",
        "\n",
        "'''\n",
        " KDE-ISOMAP \n",
        " dados: data matrix\n",
        " delta: number of points in each density (default = 256)\n",
        " k: number of neighbors in the KNN graph (patch size)\n",
        "         (this parameter has strong influence in the results)\n",
        "'''\n",
        "def NonParamISO(dados, p, d):\n",
        "    # Number of features\n",
        "    m = dados.shape[1]\n",
        "    # Number of samples\n",
        "    n = dados.shape[0]\n",
        "\n",
        "    # Creates a KNN graph from the dataset (the value of K affects the results )\n",
        "    # The second parameter is the number of neighbors K\n",
        "    esparsa = sknn.kneighbors_graph(dados, n, mode='distance', include_self=True)\n",
        "    A = esparsa.toarray()\n",
        "\n",
        "    # Calcula a distância média de xi a cada outro vértice\n",
        "    #avg_distances = A.mean(axis=1)\n",
        "    #desvpad = A.std(axis=1)\n",
        "    #med_distances = np.median(A, axis=1)\n",
        "    percentiles = np.percentile(A, p, axis=1)\n",
        "    # Se distância entre xi e xj é maior que a média, desconecta do grafo\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(A.shape[1]):\n",
        "            if A[i, j] > percentiles[i]:\n",
        "                A[i, j] = 0\n",
        "            else:\n",
        "                A[i, j] = 1\n",
        "    \n",
        "    # parameters: silverman, scott, none (default: h = 0.1), crossval\n",
        "    densidades = KernelDensityEstimation(dados, A, 'silverman')\n",
        "\n",
        "    # Matriz de pesos inicialmente igual a A\n",
        "    W = A.copy()\n",
        "    # Define the vector of KL-divergences\n",
        "    vetor_dKL = np.zeros(m)\n",
        "    # Computes the weights using de KL divergence\n",
        "    for i in range(W.shape[0]):\n",
        "        for j in range(W.shape[0]):\n",
        "            for k in range(m):\n",
        "                vetor_dKL[k] = divergenciaKL(densidades[i, :, k], densidades[j, :, k])\n",
        "            if W[i, j] > 0:\n",
        "                W[i, j] = np.dot(vetor_dKL, vetor_dKL)\n",
        "\n",
        "    # Computes geodesic distances in W\n",
        "    G = nx.from_numpy_array(W)\n",
        "    D = nx.floyd_warshall_numpy(G)   \n",
        "    # Replace infs ans nan's (in case of disconnected graphs)\n",
        "    maximo = np.nanmax(D[D != np.inf])   \n",
        "    D[np.isnan(D)] = 0    \n",
        "    D[np.isinf(D)] = 10*maximo         # ou coloca zero? \n",
        "    # Computes centering matrix H\n",
        "    H = np.eye(n, n) - (1/n)*np.ones((n, n))\n",
        "    # Computes the inner products matrix B\n",
        "    B = -0.5*H.dot(D**2).dot(H)\n",
        "    # Eigeendecomposition\n",
        "    lambdas, alphas = sp.linalg.eigh(B)\n",
        "    # Sort eigenvalues and eigenvectors\n",
        "    indices = lambdas.argsort()[::-1]\n",
        "    lambdas = lambdas[indices]\n",
        "    alphas = alphas[:, indices]\n",
        "    # Select the d largest eigenvectors\n",
        "    lambdas = lambdas[0:d]\n",
        "    alphas = alphas[:, 0:d]\n",
        "    # Computes the intrinsic coordinates\n",
        "    output = alphas*np.sqrt(lambdas)\n",
        "    \n",
        "    return output\n",
        "\n",
        "'''\n",
        " Computes the Silhouette coefficient and the supervised classification\n",
        " accuracies for several classifiers: KNN, SVM, NB, DT, QDA, MPL, GPC and RFC\n",
        " dados: learned representation (output of a dimens. reduction - DR)\n",
        " target: ground-truth (data labels)\n",
        " method: string to identify the DR method (PCA, NP-PCAKL, KPCA, ISOMAP, LLE, LAP, ...)\n",
        "'''\n",
        "def Classification(dados, target, method):\n",
        "    print()\n",
        "    print('Supervised classification for %s features' %(method))\n",
        "    print()\n",
        "    \n",
        "    lista = []\n",
        "\n",
        "    # 50% for training and 40% for testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(dados.real.T, target, test_size=.5, random_state=42)\n",
        "\n",
        "    # KNN\n",
        "    neigh = KNeighborsClassifier(n_neighbors=7)\n",
        "    neigh.fit(X_train, y_train) \n",
        "    acc = neigh.score(X_test, y_test)\n",
        "    lista.append(acc)\n",
        "    print('KNN accuracy: ', acc)\n",
        "\n",
        "    # SMV\n",
        "    svm = SVC(gamma='auto')\n",
        "    svm.fit(X_train, y_train) \n",
        "    acc = svm.score(X_test, y_test)\n",
        "    lista.append(acc)\n",
        "    print('SVM accuracy: ', acc)\n",
        "\n",
        "       # Quadratic Discriminant \n",
        "    qda = QuadraticDiscriminantAnalysis()\n",
        "    qda.fit(X_train, y_train)\n",
        "    acc = qda.score(X_test, y_test)\n",
        "    lista.append(acc)\n",
        "    print('QDA accuracy: ', acc)\n",
        "\n",
        "    # Computes the Silhoutte coefficient\n",
        "    sc = metrics.silhouette_score(dados.real.T, target, metric='euclidean')\n",
        "    print('Silhouette coefficient: ', sc)\n",
        "    \n",
        "    # Computes the average accuracy\n",
        "    #average = sum(lista)/len(lista)\n",
        "    maximo = max(lista)\n",
        "\n",
        "    print('Maximum accuracy: ', maximo)\n",
        "    print()\n",
        "\n",
        "    return [sc, maximo]\n",
        "    \n",
        "\n",
        "#%%%%%%%%%%%%%%%%%  Beginning of the script\n",
        "\n",
        "# Datasets\n",
        "X = skdata.load_iris()    \n",
        "#X = skdata.load_wine()   \n",
        "#X = skdata.fetch_openml(name='Engine1', version=1) \n",
        "#X = skdata.fetch_openml(name='prnn_crabs', version=1) \n",
        "#X = skdata.fetch_openml(name='analcatdata_happiness', version=1) \n",
        "#X = skdata.fetch_openml(name='mux6', version=1) \n",
        "#X = skdata.fetch_openml(name='parity5', version=1) \n",
        "#X = skdata.fetch_openml(name='vertebra-column', version=1) \n",
        "#X = skdata.fetch_openml(name='hayes-roth', version=2)  \n",
        "#X = skdata.fetch_openml(name='aids', version=1) \n",
        "#X = skdata.fetch_openml(name='pm10', version=2) \n",
        "#X = skdata.fetch_openml(name='strikes', version=2)  \n",
        "#X = skdata.fetch_openml(name='disclosure_z', version=2) \n",
        "#X = skdata.fetch_openml(name='diggle_table_a2', version=2) \n",
        "#X = skdata.fetch_openml(name='monks-problems-1', version=1) \n",
        "#X = skdata.fetch_openml(name='breast-tissue', version=2) \n",
        "#X = skdata.fetch_openml(name='planning-relax', version=1) \n",
        "#X = skdata.fetch_openml(name='haberman', version=1) \n",
        "#X = skdata.fetch_openml(name='rmftsa_ladata', version=2) \n",
        "#X = skdata.fetch_openml(name='KnuggetChase3', version=1) \n",
        "#X = skdata.fetch_openml(name='bolts', version=2) \n",
        "#X = skdata.fetch_openml(name='fl2000', version=2) \n",
        "#X = skdata.fetch_openml(name='triazines', version=2) \n",
        "#X = skdata.fetch_openml(name='fri_c2_100_10', version=2) \n",
        "#X = skdata.fetch_openml(name='Touch2', version=1) \n",
        "#X = skdata.fetch_openml(name='veteran', version=2) \n",
        "#X = skdata.fetch_openml(name='vineyard', version=2) \n",
        "#X = skdata.fetch_openml(name='diabetes_numeric', version=2) \n",
        "#X = skdata.fetch_openml(name='prnn_fglass', version=2) \n",
        "#X = skdata.fetch_openml(name='parkinsons', version=1) \n",
        "#X = skdata.fetch_openml(name='acute-inflammations', version=2) \n",
        "#X = skdata.fetch_openml(name='blogger', version=1) \n",
        "#X = skdata.fetch_openml(name='prnn_viruses', version=1) \n",
        "#X = skdata.fetch_openml(name='analcatdata_creditscore', version=1) \n",
        "#X = skdata.fetch_openml(name='zoo', version=1) \n",
        "#X = skdata.fetch_openml(name='confidence', version=2) \n",
        "\n",
        "\n",
        "dados = X['data']\n",
        "target = X['target']  \n",
        "\n",
        "# Number of samples\n",
        "n = dados.shape[0]\n",
        "print('Number of samples: %d' %n)\n",
        "# Number of features\n",
        "m = dados.shape[1]\n",
        "print('Number of features: %d' %m)\n",
        "# Number of classes\n",
        "c = len(np.unique(target))\n",
        "print('Number of classes: %d' %c)\n",
        "print()\n",
        "\n",
        "#%%%%%%%%%%%%%%%%%%%%%% Data processing\n",
        "# Only for OpenML datasets\n",
        "# Treat catregorical features\n",
        "if not isinstance(dados, np.ndarray):\n",
        "    cat_cols = dados.select_dtypes(['category']).columns\n",
        "    dados[cat_cols] = dados[cat_cols].apply(lambda x: x.cat.codes)\n",
        "    # Convert to numpy\n",
        "    dados = dados.to_numpy()\n",
        "    target = target.to_numpy()\n",
        "\n",
        "# Data standardization (to deal with variables having different units/scales)\n",
        "dados_nn = dados      # Save a copy of the unnormalized data\n",
        "dados = preprocessing.scale(dados)\n",
        "\n",
        "#%%%%%%%%%%% Simple PCA \n",
        "dados_pca = myPCA(dados)\n",
        "\n",
        "#%%%%%%%%%%%% Kernel PCA\n",
        "# inicio_kpca = time.time()\n",
        "model = KernelPCA(n_components=2, kernel='rbf')   \n",
        "dados_kpca = model.fit_transform(dados)\n",
        "dados_kpca = dados_kpca.T\n",
        "# fim_kpca = time.time()\n",
        "\n",
        "#%%%%%%%%%%% ISOMAP\n",
        "# inicio_iso = time.time()\n",
        "model = Isomap(n_neighbors=20, n_components=2)\n",
        "dados_isomap = model.fit_transform(dados)\n",
        "dados_isomap = dados_isomap.T\n",
        "# fim_iso = time.time()\n",
        "\n",
        "#%%%%%%%%%%% LLE\n",
        "# inicio_lle = time.time()\n",
        "model = LocallyLinearEmbedding(n_neighbors=20, n_components=2)\n",
        "dados_LLE = model.fit_transform(dados)\n",
        "dados_LLE = dados_LLE.T\n",
        "# fim_lle = time.time()\n",
        "\n",
        "#%%%%%%%%%%% Lap. Eig.\n",
        "# inicio_lap = time.time()\n",
        "model = SpectralEmbedding(n_neighbors=20, n_components=2)\n",
        "dados_Lap = model.fit_transform(dados)\n",
        "dados_Lap = dados_Lap.T\n",
        "# fim_lap = time.time()\n",
        "\n",
        "#%%%%%%%%%%% Supervised classification\n",
        "L_pca = Classification(dados_pca, target, 'PCA')\n",
        "L_kpca = Classification(dados_kpca, target, 'KPCA')\n",
        "L_iso = Classification(dados_isomap, target, 'ISOMAP')\n",
        "L_lle = Classification(dados_LLE, target, 'LLE')\n",
        "L_lap = Classification(dados_Lap, target, 'Lap. Eig.')\n",
        "\n",
        "#%%%%%%%%%%% KDE-ISOMAP\n",
        "# Number of data points in each density (ISJ as vezes precisa de muitos pontos)\n",
        "delta = 256\n",
        "\n",
        "# Number of neighbors in KNN graph\n",
        "inicio = 1\n",
        "incremento = 1\n",
        "percs = list(range(inicio, 21, incremento))\n",
        "acuracias = []\n",
        "scs = []\n",
        "\n",
        "for p in percs:\n",
        "    print('Percentile = %d' %p)\n",
        "    dados_npiso = NonParamISO(dados, p, 2)\n",
        "    #dados_npiso = NonParamISO_Mahalanobis(dados, p, 2)\n",
        "    dados_npiso = dados_npiso.T\n",
        "    L_npiso = Classification(dados_npiso, target, 'NP-ISO')\n",
        "    scs.append(L_npiso[0])\n",
        "    acuracias.append(L_npiso[1])\n",
        "\n",
        "\n",
        "print('List of values for percentiles: ', percs)\n",
        "print('Supervised classification accuracies: ', acuracias)\n",
        "acuracias = np.array(acuracias)\n",
        "print('Max Acc: ', acuracias.max())\n",
        "print('P* = ', percs[acuracias.argmax()])\n",
        "print()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(percs, acuracias)\n",
        "plt.title('Mean accuracies for different values of percentiles')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('List of values for percentiles: ', percs)\n",
        "print('Silhouette Coefficients: ', scs)\n",
        "scs = np.array(scs)\n",
        "print('Max SC: ', scs.max())\n",
        "print('P* = ', percs[scs.argmax()])\n",
        "print()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(percs, scs, color='red')\n",
        "plt.title('Silhouette coefficients for different values of percentiles')\n",
        "plt.show()\n"
      ]
    }
  ]
}